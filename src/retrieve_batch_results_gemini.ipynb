{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Batch Results from Gemini API\n",
    "\n",
    "This notebook retrieves completed batch results from the Google Gemini API.\n",
    "\n",
    "## Prerequisites\n",
    "- Set the `GEMINI_API_KEY` environment variable\n",
    "- Have a completed batch job from `create_batch_gemini.ipynb`\n",
    "- Know the path to your batch log file (created during batch submission)\n",
    "\n",
    "## Features\n",
    "- Downloads results from Gemini File API\n",
    "- Parses JSONL-formatted results\n",
    "- Tracks token usage statistics\n",
    "- Merges with existing results for incremental collection\n",
    "- Reports errors and missing results\n",
    "\n",
    "## Output Format\n",
    "```json\n",
    "{\n",
    "  \"meta_data\": {\"file_name\": \"...\", \"inference_model\": \"...\"},\n",
    "  \"token_stats\": {\"total_input_tokens\": ..., \"total_output_tokens\": ...},\n",
    "  \"results\": {\"case_001\": \"response text\", ...}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Edit these variables before running\n",
    "# ============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Base directory (should match the one used in create_batch_gemini.ipynb)\n",
    "BASE_DIR = Path(\".\")  # Change to your data directory\n",
    "\n",
    "# Settings from batch creation (must match what you used)\n",
    "INPUT_DIR = \"data\"  # Directory that contained input JSON\n",
    "INPUT_FILE = \"your_input_file\"  # Name without .json extension\n",
    "MODEL_NAME = \"gemini-2.5-pro\"  # Model used for batch\n",
    "\n",
    "# Output directory for results\n",
    "OUTPUT_DIR = BASE_DIR / \"output\"\n",
    "LOGS_DIR = BASE_DIR / \"logs\"\n",
    "\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "# Build paths\n",
    "log_path = LOGS_DIR / INPUT_DIR / MODEL_NAME / f\"{INPUT_FILE}.json\"\n",
    "output_path = OUTPUT_DIR / INPUT_DIR / MODEL_NAME / f\"{INPUT_FILE}.json\"\n",
    "\n",
    "# Load log file to get batch_job_name and key_dict\n",
    "with open(log_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "key_dict = data[\"key_dict\"]\n",
    "batch_job_name = data['batch_job']['name']\n",
    "\n",
    "print(f\"Log file: {log_path}\")\n",
    "print(f\"Batch job name: {batch_job_name}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Expected results: {len(key_dict)}\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "\n",
    "# Load existing results if any\n",
    "existing_dict = {}\n",
    "if output_path.exists():\n",
    "    with open(output_path, 'r') as f:\n",
    "        existing_dict = json.load(f)\n",
    "    print(f\"Found existing results: {len(existing_dict.get('results', {}))}\")\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nested_dicts(dict1, dict2):\n",
    "    \"\"\"Merge two dictionaries, keeping existing values on conflict.\"\"\"\n",
    "    result = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key not in result:\n",
    "            result[key] = value\n",
    "        elif isinstance(value, dict) and isinstance(result[key], dict):\n",
    "            result[key] = merge_nested_dicts(result[key], value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we already have all results\n",
    "if existing_dict:\n",
    "    existing_keys = set(existing_dict.get(\"results\", {}).keys())\n",
    "    expected_keys = set(key_dict.values())\n",
    "    \n",
    "    print(f\"Expected results: {len(expected_keys)}\")\n",
    "    print(f\"Existing results: {len(existing_keys)}\")\n",
    "    \n",
    "    if existing_keys == expected_keys:\n",
    "        print(f\"\\nAll results already collected!\")\n",
    "        print(f\"Results file: {output_path}\")\n",
    "        raise SystemExit(\"All results already collected.\")\n",
    "    elif len(existing_keys) > 0:\n",
    "        missing = expected_keys - existing_keys\n",
    "        print(f\"Missing {len(missing)} results from existing file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check batch status\n",
    "batch_job = client.batches.get(name=batch_job_name)\n",
    "print(f\"Batch job: {batch_job.name}\")\n",
    "print(f\"State: {batch_job.state.name}\")\n",
    "\n",
    "if batch_job.state.name != \"JOB_STATE_SUCCEEDED\":\n",
    "    print(f\"\\nBatch not yet completed. Status: {batch_job.state.name}\")\n",
    "    if batch_job.state.name == \"JOB_STATE_FAILED\" and hasattr(batch_job, 'error'):\n",
    "        print(f\"Error: {batch_job.error}\")\n",
    "    raise SystemExit(\"Batch not completed. Try again later.\")\n",
    "\n",
    "print(\"\\nBatch completed! Retrieving results...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse results\n",
    "if not (batch_job.dest and batch_job.dest.file_name):\n",
    "    raise ValueError(\"No result file found in batch job\")\n",
    "\n",
    "result_file_name = batch_job.dest.file_name\n",
    "print(f\"Downloading results from: {result_file_name}\")\n",
    "\n",
    "file_content = client.files.download(file=result_file_name)\n",
    "result_text = file_content.decode('utf-8')\n",
    "\n",
    "# Parse JSONL results\n",
    "result_dict = {}\n",
    "processed_keys = set()\n",
    "errors_dict = {}\n",
    "\n",
    "# Token counters\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0\n",
    "num_prompts = 0\n",
    "\n",
    "for line in result_text.strip().split('\\n'):\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        result_obj = json.loads(line)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse line: {e}\")\n",
    "        continue\n",
    "    \n",
    "    key = result_obj.get(\"key\")\n",
    "    if key is None:\n",
    "        continue\n",
    "    \n",
    "    processed_keys.add(key)\n",
    "    \n",
    "    # Check for errors\n",
    "    if \"error\" in result_obj:\n",
    "        result_key = key_dict.get(key)\n",
    "        if result_key:\n",
    "            errors_dict[result_key] = result_obj[\"error\"]\n",
    "        continue\n",
    "    \n",
    "    if \"response\" not in result_obj:\n",
    "        continue\n",
    "    \n",
    "    response = result_obj[\"response\"]\n",
    "    result_key = key_dict.get(key)\n",
    "    \n",
    "    if not result_key:\n",
    "        continue\n",
    "    \n",
    "    # Extract text from candidates\n",
    "    text_content = \"\"\n",
    "    if \"candidates\" in response and len(response[\"candidates\"]) > 0:\n",
    "        candidate = response[\"candidates\"][0]\n",
    "        if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n",
    "            for part in candidate[\"content\"][\"parts\"]:\n",
    "                if \"text\" in part:\n",
    "                    text_content += part[\"text\"]\n",
    "    \n",
    "    if text_content:\n",
    "        result_dict[result_key] = text_content\n",
    "        \n",
    "        # Extract token usage\n",
    "        if \"usageMetadata\" in response:\n",
    "            usage = response[\"usageMetadata\"]\n",
    "            total_input_tokens += usage.get(\"promptTokenCount\", 0)\n",
    "            total_output_tokens += usage.get(\"candidatesTokenCount\", 0)\n",
    "            num_prompts += 1\n",
    "\n",
    "# Calculate statistics\n",
    "token_stats = {\n",
    "    \"total_input_tokens\": total_input_tokens,\n",
    "    \"total_output_tokens\": total_output_tokens,\n",
    "    \"num_prompts\": num_prompts,\n",
    "    \"avg_input_tokens\": total_input_tokens / num_prompts if num_prompts > 0 else 0,\n",
    "    \"avg_output_tokens\": total_output_tokens / num_prompts if num_prompts > 0 else 0\n",
    "}\n",
    "\n",
    "# Report results\n",
    "missing_keys = set(key_dict.keys()) - processed_keys\n",
    "print(f\"\\nTotal submitted: {len(key_dict)}\")\n",
    "print(f\"Successful: {len(result_dict)}\")\n",
    "print(f\"Errored: {len(errors_dict)}\")\n",
    "print(f\"Missing: {len(missing_keys)}\")\n",
    "\n",
    "print(f\"\\n=== Token Statistics ===\")\n",
    "print(f\"Total input tokens: {token_stats['total_input_tokens']:,}\")\n",
    "print(f\"Total output tokens: {token_stats['total_output_tokens']:,}\")\n",
    "print(f\"Average input tokens: {token_stats['avg_input_tokens']:.1f}\")\n",
    "print(f\"Average output tokens: {token_stats['avg_output_tokens']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with existing results and save\n",
    "if existing_dict:\n",
    "    result_dict = merge_nested_dicts(existing_dict.get(\"results\", {}), result_dict)\n",
    "    \n",
    "    # Merge token stats\n",
    "    if \"token_stats\" in existing_dict:\n",
    "        old_stats = existing_dict[\"token_stats\"]\n",
    "        token_stats[\"total_input_tokens\"] += old_stats.get(\"total_input_tokens\", 0)\n",
    "        token_stats[\"total_output_tokens\"] += old_stats.get(\"total_output_tokens\", 0)\n",
    "        token_stats[\"num_prompts\"] += old_stats.get(\"num_prompts\", 0)\n",
    "        if token_stats[\"num_prompts\"] > 0:\n",
    "            token_stats[\"avg_input_tokens\"] = token_stats[\"total_input_tokens\"] / token_stats[\"num_prompts\"]\n",
    "            token_stats[\"avg_output_tokens\"] = token_stats[\"total_output_tokens\"] / token_stats[\"num_prompts\"]\n",
    "    print(\"Merged with existing results\")\n",
    "\n",
    "# Create output directory and save\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "final_dict = {\n",
    "    \"meta_data\": {\n",
    "        \"file_name\": INPUT_FILE,\n",
    "        \"inference_model\": MODEL_NAME\n",
    "    },\n",
    "    \"token_stats\": token_stats,\n",
    "    \"results\": result_dict\n",
    "}\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(final_dict, f, indent=4)\n",
    "\n",
    "print(f\"\\nSaved results to: {output_path}\")\n",
    "print(f\"Total cases with results: {len(result_dict)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
